{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25cf282-1286-4cd8-a3b3-fdc88fcbc1fa",
   "metadata": {},
   "source": [
    "# Pre-processing Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfd833f-fc66-497c-b71a-034de9e24a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp preprocessing_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf874760-d52f-43eb-8e26-eced4ddad7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35bb5155-86a4-4a74-80ef-d30ddec8f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from dicom_to_nifti import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f9d7d-1f86-4d45-8067-c84e29f45681",
   "metadata": {},
   "source": [
    "We need to load the CSV containing the series UIDs and corresponding metadata, particularly, the imaging modality, that defines the domain of a series and is used to normalize the spacing between the voxels of each volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21831725-2b0a-48a1-8894-db7b62ad80ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>SeriesInstanceUID</th><th>PatientAge</th><th>PatientSex</th><th>Modality</th><th>Left Infraclinoid Internal Carotid Artery</th><th>Right Infraclinoid Internal Carotid Artery</th><th>Left Supraclinoid Internal Carotid Artery</th><th>Right Supraclinoid Internal Carotid Artery</th><th>Left Middle Cerebral Artery</th><th>Right Middle Cerebral Artery</th><th>Anterior Communicating Artery</th><th>Left Anterior Cerebral Artery</th><th>Right Anterior Cerebral Artery</th><th>Left Posterior Communicating Artery</th><th>Right Posterior Communicating Artery</th><th>Basilar Tip</th><th>Other Posterior Circulation</th><th>Aneurysm Present</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;1.2.826.0.1.3680043.8.498.1000…</td><td>64</td><td>&quot;Female&quot;</td><td>&quot;MRA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.1000…</td><td>76</td><td>&quot;Female&quot;</td><td>&quot;MRA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 18)\n",
       "┌───────────┬───────────┬───────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ SeriesIns ┆ PatientAg ┆ PatientSe ┆ Modality ┆ … ┆ Right     ┆ Basilar   ┆ Other     ┆ Aneurysm  │\n",
       "│ tanceUID  ┆ e         ┆ x         ┆ ---      ┆   ┆ Posterior ┆ Tip       ┆ Posterior ┆ Present   │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ str      ┆   ┆ Communica ┆ ---       ┆ Circulati ┆ ---       │\n",
       "│ str       ┆ i64       ┆ str       ┆          ┆   ┆ ting …    ┆ i64       ┆ on        ┆ i64       │\n",
       "│           ┆           ┆           ┆          ┆   ┆ ---       ┆           ┆ ---       ┆           │\n",
       "│           ┆           ┆           ┆          ┆   ┆ i64       ┆           ┆ i64       ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.2.826.0 ┆ 64        ┆ Female    ┆ MRA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
       "│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 000…      ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 1.2.826.0 ┆ 76        ┆ Female    ┆ MRA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n",
       "│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 000…      ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n",
       "└───────────┴───────────┴───────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "\n",
    "base_path_dicom = os.environ['RSNA_IAD_DATA_DIR']\n",
    "series_path_dicom = f\"{base_path_dicom}/series\"\n",
    "base_path_nifti = f\"{os.environ['RSNA_IAD_DATA_DIR']}/nifti\"\n",
    "series_path_nifti = f\"{base_path_nifti}/series\"\n",
    "\n",
    "df = pl.read_csv(f\"{base_path_dicom}/train.csv\")\n",
    "display(df.head(2))\n",
    "\n",
    "LOCATION_LABELS_COLNAME = [\n",
    "    'Left Infraclinoid Internal Carotid Artery',\n",
    "    'Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery',\n",
    "    'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery',\n",
    "    'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery',\n",
    "    'Basilar Tip',\n",
    "    'Other Posterior Circulation',\n",
    "]\n",
    "\n",
    "LABELS_COLNAME =  LOCATION_LABELS_COLNAME + ['Aneurysm Present']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f7cf28-3c7f-4d19-95b7-b199f9e15c43",
   "metadata": {},
   "source": [
    "We need some functions to load NifTI files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b6aec4-e519-4f0c-b2e4-0379986ee55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import nibabel\n",
    "import torch\n",
    "\n",
    "def nifti_load(series_base_path, serie_uid):\n",
    "    nifti = nibabel.load(f\"{series_base_path}/{serie_uid}.nii.gz\")\n",
    "    return nifti\n",
    "\n",
    "def nifti_process(nifti):\n",
    "    volume = torch.from_numpy(nifti.get_fdata()).to(torch.float32)\n",
    "    metadata = nifti.header\n",
    "    return volume, metadata \n",
    "\n",
    "def nifti_get_spacing(metadata):\n",
    "    return torch.tensor(nifti.header.get_zooms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11430f04-d34d-41df-9bcc-895830755806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get volume from DICOM and corresponding nifti to test transformations on\n",
    "serie_uid = df[\"SeriesInstanceUID\"][0]\n",
    "ds_l = dicom_serie_load(series_path_dicom, serie_uid)\n",
    "volume, ds_metadata_l = dicom_serie_process(ds_l)\n",
    "dicom_volume_to_nifti(volume, ds_metadata_l, serie_uid, series_path_nifti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c876a350-538a-484f-b4a8-6197d9eb5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti = nifti_load(series_path_nifti, serie_uid)\n",
    "volume, nifti_metadata = nifti_process(nifti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2043c2c0-e230-4479-bf0b-69e1ca76c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = volume.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ade836d-1dd1-4931-b44a-037dd80de92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 188, 512, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1614598d-63d0-4916-af11-01854c448c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3516, 0.3516, 0.5000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifti_get_spacing(nifti_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da395a4-b9ec-4a1c-be5f-9cc608934504",
   "metadata": {},
   "source": [
    "All transformations are applied to a whole volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc4c945-93c9-4d4d-8a9d-c72633cbec11",
   "metadata": {},
   "source": [
    "We need functions to plot either a single volume, or two volumes, to see the original vs the transformed one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e58a751a-bc09-4650-b3bb-9cb03881dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "def plot_volume(volume, fig, ax):\n",
    "\n",
    "    volume = volume[0,0]\n",
    "\n",
    "    plt.ioff()\n",
    "    if fig is None or ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "    ax_img = ax.imshow(volume[0])  # Create and cache plot element to modify\n",
    "\n",
    "    slider = widgets.IntSlider(value=0, min=0, max=volume.shape[0]-1, step=1, description='Slice', readout=True, readout_format='d')\n",
    "\n",
    "    def update(slice_num):\n",
    "        ax_img.set_data(volume[slice_num])\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    slider.observe(lambda change: update(change[\"new\"]), names=\"value\")\n",
    "\n",
    "    return widgets.VBox([fig.canvas, slider], layout=widgets.Layout(align_items=\"center\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd00c00-b473-4c89-b9cc-9121759a6ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c99bc1c1384a2ebb20149a4f66ee8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Ba…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_volume(volume, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e18ff3b-93d9-48c5-8c81-e4ddca72aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def plot_2volumes(volume1, volume2):\n",
    "\n",
    "    ui1 = plot_volume(volume1, None, None)\n",
    "    ui2 = plot_volume(volume2, None, None)\n",
    "    return widgets.HBox([ui1, ui2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff5427f-454a-4f83-880f-680df4cf9f53",
   "metadata": {},
   "source": [
    "The `NormalizeSpacing` transformation is to normalize the spacing between the voxels, by: using the pre-calculated voxel spacing by domain; calculating the correct volume size as specified in the previous post \"Pre-calculating voxel spacings\"; and interpolating the voxels using PyTorch's `interpolate` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcd06133-2fd7-4a61-bc80-c1958c74e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NormalizeSpacing:\n",
    "\n",
    "    def __init__(self, interp_mode, domain_spacings_dict, get_metadata):\n",
    "        self.interp_mode = interp_mode\n",
    "        self.domain_spacings_dict = domain_spacings_dict\n",
    "        self.get_metadata = get_metadata        \n",
    "\n",
    "    def transform(self, volume, domain, spacing):\n",
    "\n",
    "        assert volume.dtype == torch.float32, \"Pixel array data has to be of type torch.float32.\"\n",
    "        assert len(volume.shape) == 5, \"Volume array must have 5 dimensions, i.e. (batch_size, channel_count, z, y, x).\"\n",
    "                \n",
    "        domain_spacing = torch.tensor(self.domain_spacings_dict[domain])\n",
    "        target_size = (torch.tensor(volume.shape[2:], dtype=torch.float32) / spacing * domain_spacing).to(torch.int32)\n",
    "        volume = F.interpolate(volume, size=tuple(target_size), mode=self.interp_mode)\n",
    "    \n",
    "        return volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9dd46-fdb2-4168-bfbc-a6b7a75bd32c",
   "metadata": {},
   "source": [
    "The `get_metadata` function is defined in transformations that need to get metadata from the DICOMs of a series or from other sources. This function needs to get the modality (domain) from the previously loaded DataFrame, and the spacing from the DICOMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a153c29f-bd4f-4e82-b227-823a139a23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 219, 597, 614])\n",
      "torch.Size([1, 1, 219, 597, 614])\n"
     ]
    }
   ],
   "source": [
    "volume_domain_median_spacing_dict = {\n",
    "    \"CTA\": (0.46875, 0.46875, 0.8),\n",
    "    \"MRA\": (0.410156, 0.410156, 0.6),\n",
    "    \"MRI T1post\": (0.5, 0.5, 1.2),\n",
    "    \"MRI T2\": (0.5, 0.5, 5.)\n",
    "}\n",
    "\n",
    "# DICOM\n",
    "def get_metadata_dicom(idx, ds_metadata_l):\n",
    "    modality = df[\"Modality\"][idx]\n",
    "    spacing = dicom_serie_get_spacing(ds_metadata_l)\n",
    "    return modality, spacing\n",
    "\n",
    "transform = NormalizeSpacing(\"nearest\", volume_domain_median_spacing_dict, get_metadata_dicom)\n",
    "transform_metadata = transform.get_metadata(0, ds_metadata_l)\n",
    "transformed_volume = transform.transform(volume, *transform_metadata)\n",
    "print(transformed_volume.shape)\n",
    "\n",
    "# NifTI\n",
    "def get_metadata_nifti(idx, metadata):\n",
    "    modality = df[\"Modality\"][idx]\n",
    "    spacing = nifti_get_spacing(metadata)\n",
    "    return modality, spacing\n",
    "\n",
    "transform = NormalizeSpacing(\"nearest\", volume_domain_median_spacing_dict, get_metadata_nifti)\n",
    "transform_metadata = transform.get_metadata(0, nifti_metadata)\n",
    "transformed_volume = transform.transform(volume, *transform_metadata)\n",
    "print(transformed_volume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2686b994-5cc7-469d-9a56-0068c1d9449f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509e0dd38e8f4f1d9e20206c0ed34ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'…"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_2volumes(volume, transformed_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe3c75-af84-4136-be2e-38832cb9c71b",
   "metadata": {},
   "source": [
    "The `ResizeInterp` resizes the image by interpolating with the PyTorch's `interpolate` function. It can interpolate voxels using nearest neighbors (\"nearest\"/\"nearest-exact\"), \"trilinear\" and \"area\" (average pooling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b863d5f-4c08-4a2c-9396-f675649165f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ResizeInterp:\n",
    "\n",
    "    get_metadata = None\n",
    "    \n",
    "    def __init__(self, target_size, mode):\n",
    "        self.target_size = target_size\n",
    "        self.mode = mode    \n",
    "\n",
    "    def transform(self, volume):\n",
    "    \n",
    "        assert volume.dtype == torch.float32, \"Pixel array data has to be of type torch.float32\"\n",
    "        \n",
    "        volume = F.interpolate(volume, size=self.target_size, mode=self.mode)\n",
    "        return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c8fb0ce-71ff-4947-b022-ec8015fb63aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "transform = ResizeInterp((32, 224, 224), \"nearest\")\n",
    "transformed_volume = transform.transform(volume)\n",
    "print(transformed_volume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9734608-61a5-4b42-9062-84579a2fcfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df595ece366c4cf1a5757a1de402c73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'…"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_2volumes(volume, transformed_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251acd9d-2a65-4a15-9f84-2334e657ded9",
   "metadata": {},
   "source": [
    "The `PercentileCropIntensity` transformation clamps voxel values between two percentiles, so outliers are removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40b8f20a-b6d2-4e9b-9169-cf976d4debc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import numpy as np\n",
    "\n",
    "class PercentileCropIntensity:\n",
    "\n",
    "    get_metadata = None\n",
    "\n",
    "    def __init__(self, percentiles):\n",
    "        self.percentiles = percentiles\n",
    "    \n",
    "    def transform(self, volume):\n",
    "        percentiles = np.percentile(volume.flatten().detach().cpu().numpy(), self.percentiles)\n",
    "        volume = torch.clamp(volume, min=percentiles[0], max=percentiles[1])\n",
    "        return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7621d6b-b6f5-4960-a060-c594447cead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(682.)\n",
      "tensor(0.) tensor(131.)\n"
     ]
    }
   ],
   "source": [
    "transform = PercentileCropIntensity((0.5, 99.5))\n",
    "transformed_volume = transform.transform(volume)\n",
    "print(volume.min(), volume.max())\n",
    "print(transformed_volume.min(), transformed_volume.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dfb1b-9a1d-480c-834f-95f8f31a8e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07efdd8a32974ee18db4f00cf7ce7b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'…"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_2volumes(volume, transformed_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd54233-7d0a-43be-b20d-e7ec74a892ff",
   "metadata": {},
   "source": [
    "The `StandardizeIntensity` transformation normalizes the voxel values so they have mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa5ce677-3181-45f3-adf3-0509cbe8eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class StandardizeIntensity:\n",
    "\n",
    "    get_metadata = None\n",
    "    \n",
    "    def transform(self, volume):\n",
    "\n",
    "        assert volume.dtype == torch.float32, \\\n",
    "        \"Pixel array data has to be of type torch.float32\"\n",
    "    \n",
    "        volume = (volume - volume.mean()) / volume.std()\n",
    "        \n",
    "        return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c752537e-dd4e-447d-ab2e-f7367b7aeebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.0727e-09) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "transform = StandardizeIntensity()\n",
    "transformed_volume = transform.transform(volume)\n",
    "print(transformed_volume.mean(), transformed_volume.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0582a760-aaeb-4bb5-b49a-3d812369c9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b3f2c3ba504f789d034f7cf7f1fa7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'…"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_2volumes(volume, transformed_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee7fb5e-aa18-47d9-bc90-5c31eb2b0d98",
   "metadata": {},
   "source": [
    "Now let's use the PyTorch `Dataset` class to later use the `DataLoader` class to load and transform the volumes in parallel.\n",
    "First we implement `Dataset` classes that load and transform a single series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31a4312e-8ada-455b-9d7e-cc8218e62eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, path, series_uid_l, labels, transforms):\n",
    "        self.path = path\n",
    "        self.series_uid_l = series_uid_l\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.n = len(self.series_uid_l)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "437775cf-5df5-4d31-b9b3-4dfaeb2bc138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pydicom\n",
    "\n",
    "class DicomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, series_uid_l, labels, transforms):\n",
    "        super().__init__(path, series_uid_l, labels, transforms)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        serie_uid = self.series_uid_l[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        ds_l = dicom_serie_load(self.path, serie_uid)\n",
    "        volume, ds_metadata_l = dicom_serie_process(ds_l)\n",
    "        volume = volume.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        for transform in self.transforms:\n",
    "            if transform.get_metadata is not None:\n",
    "                transform_metadata = transform.get_metadata(idx, ds_metadata_l)\n",
    "                volume = transform.transform(volume, *transform_metadata)\n",
    "            else:\n",
    "                volume = transform.transform(volume)\n",
    "\n",
    "        return volume[0], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dee30435-a4ae-4aa1-94c8-0ae3894c8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    NormalizeSpacing(\"trilinear\", volume_domain_median_spacing_dict, get_metadata_dicom),\n",
    "    PercentileCropIntensity(percentiles=(0.5, 99.5)),\n",
    "    StandardizeIntensity(), \n",
    "    ResizeInterp((32, 224, 224), \"nearest\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75502a00-c36d-4903-a7ea-ff50519f8386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 224, 224]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "dicom_dataset = DicomDataset(series_path_dicom, \n",
    "                             list(df[\"SeriesInstanceUID\"]), \n",
    "                             torch.from_numpy(df[LABELS_COLNAME].to_numpy()),\n",
    "                             transforms)\n",
    "\n",
    "volume, label = next(iter(dicom_dataset))\n",
    "print(volume.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3abd168-fe91-4489-81ac-7a4d8bdcec6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c4466b01cd47d78cfceccec899529f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Ba…"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_volume(volume.unsqueeze(0), None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2558392c-68fc-4b0b-ab24-84dd59d74c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class NiftiDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, series_uid_l, labels, transforms):\n",
    "        super().__init__(path, series_uid_l, labels, transforms)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        serie_uid = self.series_uid_l[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        nifti = nifti_load(self.path, serie_uid)\n",
    "        volume, metadata = nifti_process(nifti)\n",
    "        volume = volume.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        for transform in self.transforms:\n",
    "            if transform.get_metadata is not None:\n",
    "                transform_metadata = transform.get_metadata(idx, metadata)\n",
    "                volume = transform.transform(volume, *transform_metadata)\n",
    "            else:\n",
    "                volume = transform.transform(volume)\n",
    "\n",
    "        return volume[0], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aea335c4-2a08-4583-a7e8-ac3a0421fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    NormalizeSpacing(\"trilinear\", volume_domain_median_spacing_dict, get_metadata_nifti),\n",
    "    PercentileCropIntensity(percentiles=(0.5, 99.5)),\n",
    "    StandardizeIntensity(), \n",
    "    ResizeInterp((32, 224, 224), \"nearest\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65f2bc2b-cf31-45e3-9438-0d4d37cae417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 224, 224]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "nifti_dataset = NiftiDataset(series_path_nifti, \n",
    "                             list(df[\"SeriesInstanceUID\"]), \n",
    "                             torch.from_numpy(df[LABELS_COLNAME].to_numpy()),\n",
    "                             transforms)\n",
    "\n",
    "volume, label = next(iter(nifti_dataset))\n",
    "print(volume.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef863eba-ab1d-43a8-9b42-aa1b824fd2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e61ee22d2cd42d290e8d249b5001a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Ba…"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_volume(volume.unsqueeze(0), None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b2470f-a709-474d-afab-4106293f6ad5",
   "metadata": {},
   "source": [
    "Now lets build the DataLoaders to load and transform the data in parallel and, optionally, returns it in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2da3e439-5f7d-4c62-b8bd-13bd8ae5bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import multiprocessing\n",
    "\n",
    "class DicomDataLoader:\n",
    "\n",
    "    def __init__(self, path, series_uid_l, labels, unit_transforms,\n",
    "                 shuffle, batch_size, pin_memory, num_workers):\n",
    "        dataset = DicomDataset(path, series_uid_l, labels, unit_transforms)\n",
    "        self.loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                  shuffle=shuffle, pin_memory=pin_memory,\n",
    "                                                  num_workers=num_workers)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for volumes, labels in self.loader:\n",
    "            yield volumes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "230b5956-9e68-440c-bb06-ebe294cb4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    NormalizeSpacing(\"trilinear\", volume_domain_median_spacing_dict, get_metadata_dicom),\n",
    "    PercentileCropIntensity(percentiles=(0.5, 99.5)),\n",
    "    StandardizeIntensity(), \n",
    "    ResizeInterp((32, 224, 224), \"nearest\")\n",
    "]\n",
    "\n",
    "dicom_loader = DicomDataLoader(series_path_dicom, \n",
    "                               list(df[\"SeriesInstanceUID\"]), \n",
    "                               torch.from_numpy(df[LABELS_COLNAME].to_numpy()),\n",
    "                               transforms, \n",
    "                               shuffle=True, batch_size=4, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc047b01-d70a-4670-be94-a29ea3dfc24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afonsomm/micromamba/envs/rsna_iad/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 32, 224, 224]) tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for volumes, labels in dicom_loader:\n",
    "    print(volumes.shape, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5434f881-51d1-472c-83df-081e32fe6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class NiftiDataLoader:\n",
    "\n",
    "    def __init__(self, path, series_uid_l, labels, unit_transforms,\n",
    "                 shuffle, batch_size, pin_memory, num_workers):\n",
    "        dataset = NiftiDataset(path, series_uid_l, labels, unit_transforms)\n",
    "        self.loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                  shuffle=shuffle, pin_memory=pin_memory,\n",
    "                                                  num_workers=num_workers)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for volumes, labels in self.loader:\n",
    "            yield volumes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c9357c7-1cd2-4339-b2c3-38e2a77f10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    NormalizeSpacing(\"trilinear\", volume_domain_median_spacing_dict, get_metadata_nifti),\n",
    "    PercentileCropIntensity(percentiles=(0.5, 99.5)),\n",
    "    StandardizeIntensity(), \n",
    "    ResizeInterp((32, 224, 224), \"nearest\")\n",
    "]\n",
    "\n",
    "nifti_loader = NiftiDataLoader(series_path_nifti, \n",
    "                               list(map(lambda x: x[:-7], os.listdir(series_path_nifti))), \n",
    "                               torch.from_numpy(df[LABELS_COLNAME].to_numpy()),\n",
    "                               transforms, \n",
    "                               shuffle=True, batch_size=4, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06761922-485d-45fd-afc1-4d1aa31678fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 32, 224, 224]) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "for volumes, labels in nifti_loader:\n",
    "    print(volumes.shape, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97560f84-e043-4e09-9dd8-fb109d89ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import nb_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0621cf20-210c-4941-b346-a05c9b787099",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_export(\"4_preprocessing_volumes.ipynb\", \"../lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551bfb8-ba07-487d-bc06-4fb312d3bb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
