{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3afd91-541c-4157-9233-c76088af2ed4",
   "metadata": {},
   "source": [
    "# Submission Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e211a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:13.116213Z",
     "iopub.status.busy": "2025-10-14T20:45:13.115977Z",
     "iopub.status.idle": "2025-10-14T20:45:15.177011Z",
     "shell.execute_reply": "2025-10-14T20:45:15.176278Z"
    },
    "papermill": {
     "duration": 2.066749,
     "end_time": "2025-10-14T20:45:15.178579",
     "exception": false,
     "start_time": "2025-10-14T20:45:13.111830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import kaggle_evaluation.rsna_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e9ae55-83ed-4fa6-8995-1b1675f3ec03",
   "metadata": {},
   "source": [
    "Here we put all the code used in this notebook and do not import it from Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b4b3904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:15.192004Z",
     "iopub.status.busy": "2025-10-14T20:45:15.191705Z",
     "iopub.status.idle": "2025-10-14T20:45:15.196146Z",
     "shell.execute_reply": "2025-10-14T20:45:15.195593Z"
    },
    "papermill": {
     "duration": 0.009926,
     "end_time": "2025-10-14T20:45:15.197395",
     "exception": false,
     "start_time": "2025-10-14T20:45:15.187469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ID_COL = 'SeriesInstanceUID'\n",
    "\n",
    "LABEL_COLS = [\n",
    "    'Left Infraclinoid Internal Carotid Artery',\n",
    "    'Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery',\n",
    "    'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery',\n",
    "    'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery',\n",
    "    'Basilar Tip',\n",
    "    'Other Posterior Circulation',\n",
    "    'Aneurysm Present',\n",
    "]\n",
    "\n",
    "# All tags (other than PixelData and SeriesInstanceUID) that may be in a test set dcm file\n",
    "DICOM_TAG_ALLOWLIST = [\n",
    "    'BitsAllocated',\n",
    "    'BitsStored',\n",
    "    'Columns',\n",
    "    'FrameOfReferenceUID',\n",
    "    'HighBit',\n",
    "    'ImageOrientationPatient',\n",
    "    'ImagePositionPatient',\n",
    "    'InstanceNumber',\n",
    "    'Modality',\n",
    "    'PatientID',\n",
    "    'PhotometricInterpretation',\n",
    "    'PixelRepresentation',\n",
    "    'PixelSpacing',\n",
    "    'PlanarConfiguration',\n",
    "    'RescaleIntercept',\n",
    "    'RescaleSlope',\n",
    "    'RescaleType',\n",
    "    'Rows',\n",
    "    'SOPClassUID',\n",
    "    'SOPInstanceUID',\n",
    "    'SamplesPerPixel',\n",
    "    'SliceThickness',\n",
    "    'SpacingBetweenSlices',\n",
    "    'StudyInstanceUID',\n",
    "    'TransferSyntaxUID',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5d41c-f111-4c71-b6c1-d3e9f9b42842",
   "metadata": {},
   "source": [
    "I change some functions to make the code robust to changes in the test set from the provided training set. Like in `dicom_serie_load`, I recursively obtain the file paths in a given base path, and filter only for \".dcm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3686bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:15.209831Z",
     "iopub.status.busy": "2025-10-14T20:45:15.209631Z",
     "iopub.status.idle": "2025-10-14T20:45:19.231573Z",
     "shell.execute_reply": "2025-10-14T20:45:19.230976Z"
    },
    "papermill": {
     "duration": 4.026513,
     "end_time": "2025-10-14T20:45:19.232905",
     "exception": false,
     "start_time": "2025-10-14T20:45:15.206392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "\n",
    "def dicom_serie_load(serie_path):\n",
    "\n",
    "    instances_filename = os.listdir(serie_path)\n",
    "    \n",
    "    ds_l = []\n",
    "    for root, _, filenames in os.walk(serie_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".dcm\"):\n",
    "                ds = pydicom.dcmread(f\"{root}/{filename}\")\n",
    "                ds_l.append(ds)\n",
    "\n",
    "    return ds_l\n",
    "\n",
    "\n",
    "def dicom_get_zposition(ds):\n",
    "    \n",
    "    if getattr(ds, \"ImagePositionPatient\", None) and len(ds.ImagePositionPatient) >= 3:\n",
    "        z_position = ds.ImagePositionPatient[2]\n",
    "    else:  # in case the tag is missing or does not contain the z axis position\n",
    "        z_position = getattr(ds, \"InstanceNumber\", 0.0)\n",
    "\n",
    "    return float(z_position)\n",
    "\n",
    "\n",
    "def dicom_get_rescale_factors(ds):\n",
    "\n",
    "    slope = getattr(ds, \"RescaleSlope\", 1.0)\n",
    "    intercept = getattr(ds, \"RescaleIntercept\", 0.0)\n",
    "    \n",
    "    return float(slope), float(intercept)\n",
    "    \n",
    "\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "def dicom_split_array_from_metadata(ds):  # process a single DICOM\n",
    "\n",
    "    ds_copy = deepcopy(ds)  # copy the dicom object\n",
    "    pixel_pt = torch.from_numpy(ds_copy.pixel_array)\n",
    "    del ds_copy.PixelData  # remove pixel data from the dicom object copy\n",
    "    \n",
    "    return pixel_pt, ds_copy\n",
    "\n",
    "\n",
    "def dicom_serie_process(ds_l):\n",
    "\n",
    "    n_ds = len(ds_l)\n",
    "\n",
    "    pixel_pt, ds_metadata = dicom_split_array_from_metadata(ds_l[0])  # Get first instance\n",
    "\n",
    "    if n_ds == 1:  # one dicom with the whole volume\n",
    "        volume = pixel_pt\n",
    "        ds_metadata_l = [ds_metadata]\n",
    "    else:  # each dicom with a slice\n",
    "        volume = torch.zeros((n_ds, *pixel_pt.shape), dtype=torch.float32)\n",
    "        ds_metadata_l = [None] * n_ds\n",
    "        volume[0] = pixel_pt\n",
    "        ds_metadata_l[0] = ds_metadata\n",
    "\n",
    "        # To later sort the slices\n",
    "        zpositions = torch.zeros((n_ds,), dtype=torch.float32)\n",
    "        zpositions[0] = dicom_get_zposition(ds_l[0])\n",
    "        \n",
    "        for i, ds in enumerate(ds_l[1:], start=1):\n",
    "            volume[i], ds_metadata_l[i] = dicom_split_array_from_metadata(ds)\n",
    "            zpositions[i] = dicom_get_zposition(ds)\n",
    "\n",
    "\t\t# sort slices in the volume\n",
    "        zpositions_argsort = torch.argsort(zpositions)\n",
    "        volume = volume[zpositions_argsort]\n",
    "\t\n",
    "    # rescale volume\n",
    "    slope, intercept = dicom_get_rescale_factors(ds_l[0])\n",
    "    volume = volume * slope + intercept\n",
    "    \n",
    "    return volume, ds_metadata_l\n",
    "\n",
    "\n",
    "def dicom_get_spacing(ds):\n",
    "\n",
    "    pixel_spacing = getattr(ds, \"PixelSpacing\", None)\n",
    "    slice_thickness = getattr(ds, \"SliceThickness\", None)\n",
    "\n",
    "    if (pixel_spacing is None) or (slice_thickness is None):\n",
    "        shared_functional_groups_sequence = getattr(ds, \"SharedFunctionalGroupsSequence\", None)\n",
    "        if shared_functional_groups_sequence is not None:\n",
    "            pixel_measures_sequence = getattr(shared_functional_groups_sequence[0], \"PixelMeasuresSequence\", None)\n",
    "            if pixel_measures_sequence is not None:\n",
    "                if pixel_spacing is None:\n",
    "                    pixel_spacing = getattr(pixel_measures_sequence[0], \"PixelSpacing\", None)\n",
    "                if slice_thickness is None:\n",
    "                    slice_thickness = getattr(pixel_measures_sequence[0], \"SliceThickness\", None)\n",
    "    \n",
    "    if pixel_spacing is None:\n",
    "        pixel_spacing = [0.0, 0.0]\n",
    "    else:\n",
    "        pixel_spacing = [float(axis_spacing) for axis_spacing in pixel_spacing]\n",
    "    \n",
    "    if slice_thickness is None:\n",
    "        slice_thickness = 0.0\n",
    "    else:\n",
    "        slice_thickness = float(slice_thickness)\n",
    "    \n",
    "    spacing = [*pixel_spacing, slice_thickness]\n",
    "\n",
    "    return spacing\n",
    "\n",
    "\n",
    "def dicom_serie_get_spacing(ds_l):\n",
    "\n",
    "    spacings = torch.zeros((len(ds_l), 3), requires_grad=False)\n",
    "    for i, ds in enumerate(ds_l):\n",
    "        spacings[i] = torch.tensor(dicom_get_spacing(ds))\n",
    "\n",
    "    return spacings.mode(dim=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a451ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:19.244916Z",
     "iopub.status.busy": "2025-10-14T20:45:19.244598Z",
     "iopub.status.idle": "2025-10-14T20:45:19.251662Z",
     "shell.execute_reply": "2025-10-14T20:45:19.251203Z"
    },
    "papermill": {
     "duration": 0.011329,
     "end_time": "2025-10-14T20:45:19.252615",
     "exception": false,
     "start_time": "2025-10-14T20:45:19.241286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class NormalizeSpacing:\n",
    "\n",
    "    def __init__(self, interp_mode, domain_spacings_dict, get_metadata):\n",
    "        self.interp_mode = interp_mode\n",
    "        self.domain_spacings_dict = domain_spacings_dict\n",
    "        self.get_metadata = get_metadata        \n",
    "\n",
    "    def transform(self, volume, domain, spacing):\n",
    "\n",
    "        volume = volume.to(torch.float32)\n",
    "\n",
    "        if domain in self.domain_spacings_dict:\n",
    "            domain_spacing = torch.tensor(self.domain_spacings_dict[domain])\n",
    "        else:\n",
    "            domain_spacing = spacing\n",
    "        \n",
    "        target_size = (torch.tensor(volume.shape[2:], dtype=torch.float32) / spacing * domain_spacing).to(torch.int32)\n",
    "        volume = F.interpolate(volume, size=tuple(target_size), mode=self.interp_mode)\n",
    "    \n",
    "        return volume\n",
    "\n",
    "\n",
    "class NormalizeSizeInterp:\n",
    "\n",
    "    get_metadata = None\n",
    "    \n",
    "    def __init__(self, target_size, mode):\n",
    "        self.target_size = target_size\n",
    "        self.mode = mode    \n",
    "\n",
    "    def transform(self, volume):\n",
    "    \n",
    "        volume = volume.to(torch.float32)\n",
    "        \n",
    "        volume = F.interpolate(volume, size=self.target_size, mode=self.mode)\n",
    "        return volume\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class PercentileCropIntensity:\n",
    "\n",
    "    get_metadata = None\n",
    "\n",
    "    def __init__(self, percentiles):\n",
    "        self.percentiles = percentiles\n",
    "    \n",
    "    def transform(self, volume):\n",
    "        percentiles = np.percentile(volume.flatten().detach().cpu().numpy(), self.percentiles)\n",
    "        volume = torch.clamp(volume, min=percentiles[0], max=percentiles[1])\n",
    "        return volume\n",
    "\n",
    "\n",
    "class StandardizeIntensity:\n",
    "\n",
    "    get_metadata = None\n",
    "    \n",
    "    def transform(self, volume):\n",
    "\n",
    "        volume = volume.to(torch.float32)\n",
    "    \n",
    "        volume = (volume - volume.mean()) / volume.std()\n",
    "        \n",
    "        return volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1be060-4a94-4e39-809f-ce2498c45d4c",
   "metadata": {},
   "source": [
    "Since the Kaggle server that performs inference does not have access to the Internet, we have to copy and paste all the ResNet50 code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6de6f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:19.263850Z",
     "iopub.status.busy": "2025-10-14T20:45:19.263667Z",
     "iopub.status.idle": "2025-10-14T20:45:19.279735Z",
     "shell.execute_reply": "2025-10-14T20:45:19.279202Z"
    },
    "papermill": {
     "duration": 0.02042,
     "end_time": "2025-10-14T20:45:19.280771",
     "exception": false,
     "start_time": "2025-10-14T20:45:19.260351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# -------------------- Copied from https://github.com/Warvito/MedicalNet-models/blob/main/medicalnet_models/models/resnet.py\n",
    "def conv3x3x3(in_planes: int, out_planes: int, stride: int = 1, dilation: int = 1) -> nn.Conv3d:\n",
    "    \"\"\"3x3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv3d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        dilation=dilation,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        bias=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv3d:\n",
    "    \"\"\"1x1x1 convolution\"\"\"\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: nn.Module = None,\n",
    "        dilation: int = 1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = conv3x3x3(inplanes, planes, stride=stride, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: nn.Module = None,\n",
    "        dilation: int = 1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = conv1x1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = conv3x3x3(\n",
    "            planes,\n",
    "            planes,\n",
    "            stride=stride,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = conv1x1x1(planes, planes * 4)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block,\n",
    "        layers,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.layers = layers\n",
    "\n",
    "        self.conv1 = nn.Conv3d(1, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n",
    "\n",
    "    def _make_layer(\n",
    "        self, block, planes: int, blocks: int, stride: int = 1, dilation: int = 1\n",
    "    ):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1x1(\n",
    "                    self.inplanes,\n",
    "                    planes * block.expansion,\n",
    "                    stride=stride,\n",
    "                ),\n",
    "                nn.BatchNorm3d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes,\n",
    "                planes,\n",
    "                stride=stride,\n",
    "                dilation=dilation,\n",
    "                downsample=downsample,\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        return x\n",
    "# --------------------\n",
    "\n",
    "class MedResNet(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        self.pretrained = ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.linear = nn.Linear(2048, out_features, bias=False)\n",
    "        self.linear.weight = nn.init.xavier_normal_(self.linear.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained.forward(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = x.squeeze(dim=(2,3,4))\n",
    "        x = self.linear(x)\n",
    "        if not self.training:  # training uses BCEWithLogitsLoss\n",
    "            x = F.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626ad4c-e68a-4cf4-81d3-277dee15f790",
   "metadata": {},
   "source": [
    "Now we write the prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66c6bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:19.294425Z",
     "iopub.status.busy": "2025-10-14T20:45:19.294223Z",
     "iopub.status.idle": "2025-10-14T20:45:21.293667Z",
     "shell.execute_reply": "2025-10-14T20:45:21.292617Z"
    },
    "papermill": {
     "duration": 2.004531,
     "end_time": "2025-10-14T20:45:21.295461",
     "exception": false,
     "start_time": "2025-10-14T20:45:19.290930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# -- Transforms\n",
    "volume_domain_median_spacing_dict = {\n",
    "    \"CT\": (0.46875, 0.46875, 0.8),\n",
    "    \"MR\": (0.410156, 0.410156, 0.6),\n",
    "}\n",
    "\n",
    "def get_metadata_dicom(ds_metadata_l):\n",
    "    modality = ds_metadata_l[0].Modality\n",
    "    spacing = dicom_serie_get_spacing(ds_metadata_l)\n",
    "    return modality, spacing\n",
    "\n",
    "transforms = [\n",
    "    NormalizeSpacing(\"trilinear\", volume_domain_median_spacing_dict, get_metadata_dicom),\n",
    "    PercentileCropIntensity(percentiles=(0.5, 99.5)),\n",
    "    StandardizeIntensity(), \n",
    "    NormalizeSizeInterp((32, 224, 224), \"nearest\")\n",
    "]\n",
    "\n",
    "# -- Device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# -- Model\n",
    "model_resnet50 = MedResNet(14)\n",
    "model_resnet50.load_state_dict(torch.load(\"/kaggle/input/med3d-resnet50-rsna-iad/pytorch/default/1/resnet50.pth\", weights_only=True))\n",
    "model_resnet50.eval()\n",
    "model_resnet50 = model_resnet50.to(device)\n",
    "\n",
    "def _predict(series_path: str):\n",
    "    \n",
    "    # -- Load and Transform\n",
    "    ds_l = dicom_serie_load(series_path)\n",
    "    volume, ds_metadata_l = dicom_serie_process(ds_l)\n",
    "\n",
    "    ndim = len(volume.shape)\n",
    "    if ndim < 5:\n",
    "        for _ in range(5 - ndim):\n",
    "            volume = volume.unsqueeze(0)\n",
    "    \n",
    "    for transform in transforms:\n",
    "        if transform.get_metadata is not None:\n",
    "            transform_metadata = transform.get_metadata(ds_metadata_l)\n",
    "            volume = transform.transform(volume, *transform_metadata)\n",
    "        else:\n",
    "            volume = transform.transform(volume)\n",
    "    \n",
    "    # -- Predict\n",
    "    with torch.no_grad():\n",
    "        volume = volume.to(device)\n",
    "        volume = volume.nan_to_num(posinf=0.0, neginf=0.0)\n",
    "        scores = model_resnet50.forward(volume)\n",
    "        \n",
    "        if (scores[:, :-1] > 0.5).any().item():\n",
    "            scores[:, -1] = 1.0\n",
    "        else:\n",
    "            scores[:, -1] = 0.0\n",
    "\n",
    "    # -- Make polars DataFrame\n",
    "    series_id = os.path.basename(series_path)\n",
    "    predictions = pl.DataFrame(\n",
    "        data=[[series_id] + scores[0].tolist()],\n",
    "        schema=[ID_COL, *LABEL_COLS],\n",
    "        orient='row',\n",
    "    )\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8484b0f-bb01-47c0-bfba-bd88e2da53ea",
   "metadata": {},
   "source": [
    "For the script to run until the end we will use a `try: ... except: ...` block with a fallback function in the case the prediction function fails for some reason: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0060bf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:21.301858Z",
     "iopub.status.busy": "2025-10-14T20:45:21.301642Z",
     "iopub.status.idle": "2025-10-14T20:45:21.305331Z",
     "shell.execute_reply": "2025-10-14T20:45:21.304824Z"
    },
    "papermill": {
     "duration": 0.007921,
     "end_time": "2025-10-14T20:45:21.306357",
     "exception": false,
     "start_time": "2025-10-14T20:45:21.298436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _fallback(series_path: str):\n",
    "\n",
    "    series_id = os.path.basename(series_path)\n",
    "    predictions = pl.DataFrame(\n",
    "        data=[[series_id] + [0.5] * len(LABEL_COLS)],\n",
    "        schema=[ID_COL, *LABEL_COLS],\n",
    "        orient='row',\n",
    "    )\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3845f6b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:21.312368Z",
     "iopub.status.busy": "2025-10-14T20:45:21.312163Z",
     "iopub.status.idle": "2025-10-14T20:45:21.316807Z",
     "shell.execute_reply": "2025-10-14T20:45:21.316151Z"
    },
    "papermill": {
     "duration": 0.008725,
     "end_time": "2025-10-14T20:45:21.317794",
     "exception": false,
     "start_time": "2025-10-14T20:45:21.309069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace this function with your inference code.\n",
    "# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n",
    "# Each prediction (except the very first) must be returned within 30 minutes of the series being provided.\n",
    "def predict(series_path: str) -> pl.DataFrame:\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        predictions = _predict(series_path)\n",
    "    except Exception:\n",
    "        predictions = _fallback(series_path)\n",
    "\n",
    "    if isinstance(predictions, pl.DataFrame):\n",
    "        assert predictions.columns == [ID_COL, *LABEL_COLS]\n",
    "    elif isinstance(predictions, pd.DataFrame):\n",
    "        assert (predictions.columns == [ID_COL, *LABEL_COLS]).all()\n",
    "    else:\n",
    "        raise TypeError('The predict function must return a DataFrame')\n",
    "\n",
    "    # ----------------------------- IMPORTANT ------------------------------\n",
    "    # You MUST have the following code in your `predict` function\n",
    "    # to prevent \"out of disk space\" errors. This is a temporary workaround\n",
    "    # as we implement improvements to our evaluation system.\n",
    "    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    return predictions.drop(ID_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcea4cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:21.324100Z",
     "iopub.status.busy": "2025-10-14T20:45:21.323846Z",
     "iopub.status.idle": "2025-10-14T20:45:21.326681Z",
     "shell.execute_reply": "2025-10-14T20:45:21.326067Z"
    },
    "papermill": {
     "duration": 0.007167,
     "end_time": "2025-10-14T20:45:21.327641",
     "exception": false,
     "start_time": "2025-10-14T20:45:21.320474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Small test\n",
    "#predict(\"/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10012790035410518400400834395242853657\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44bc432b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T20:45:21.338602Z",
     "iopub.status.busy": "2025-10-14T20:45:21.338408Z",
     "iopub.status.idle": "2025-10-14T20:45:41.562581Z",
     "shell.execute_reply": "2025-10-14T20:45:41.561803Z"
    },
    "papermill": {
     "duration": 20.22842,
     "end_time": "2025-10-14T20:45:41.563810",
     "exception": false,
     "start_time": "2025-10-14T20:45:21.335390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>SeriesInstanceUID</th><th>Left Infraclinoid Internal Carotid Artery</th><th>Right Infraclinoid Internal Carotid Artery</th><th>Left Supraclinoid Internal Carotid Artery</th><th>Right Supraclinoid Internal Carotid Artery</th><th>Left Middle Cerebral Artery</th><th>Right Middle Cerebral Artery</th><th>Anterior Communicating Artery</th><th>Left Anterior Cerebral Artery</th><th>Right Anterior Cerebral Artery</th><th>Left Posterior Communicating Artery</th><th>Right Posterior Communicating Artery</th><th>Basilar Tip</th><th>Other Posterior Circulation</th><th>Aneurysm Present</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;1.2.826.0.1.3680043.8.498.1007…</td><td>0.006142</td><td>0.005146</td><td>0.037685</td><td>0.023692</td><td>0.038315</td><td>0.025038</td><td>0.106118</td><td>0.001882</td><td>0.007146</td><td>0.008368</td><td>0.006331</td><td>0.008048</td><td>0.008292</td><td>0.0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.1002…</td><td>0.016863</td><td>0.011341</td><td>0.054065</td><td>0.034428</td><td>0.023518</td><td>0.023615</td><td>0.038864</td><td>0.002557</td><td>0.003989</td><td>0.008769</td><td>0.010296</td><td>0.007462</td><td>0.018473</td><td>0.0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.1005…</td><td>0.018186</td><td>0.024549</td><td>0.05438</td><td>0.037644</td><td>0.056714</td><td>0.054527</td><td>0.086452</td><td>0.01043</td><td>0.009046</td><td>0.015601</td><td>0.033935</td><td>0.021262</td><td>0.029377</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 15)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ SeriesIns ┆ Left Infr ┆ Right Inf ┆ Left Supr ┆ … ┆ Right     ┆ Basilar   ┆ Other     ┆ Aneurysm │\n",
       "│ tanceUID  ┆ aclinoid  ┆ raclinoid ┆ aclinoid  ┆   ┆ Posterior ┆ Tip       ┆ Posterior ┆ Present  │\n",
       "│ ---       ┆ Internal  ┆ Internal  ┆ Internal  ┆   ┆ Communica ┆ ---       ┆ Circulati ┆ ---      │\n",
       "│ str       ┆ Car…      ┆ Ca…       ┆ Car…      ┆   ┆ ting …    ┆ f64       ┆ on        ┆ f64      │\n",
       "│           ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆           ┆ ---       ┆          │\n",
       "│           ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆           ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 1.2.826.0 ┆ 0.006142  ┆ 0.005146  ┆ 0.037685  ┆ … ┆ 0.006331  ┆ 0.008048  ┆ 0.008292  ┆ 0.0      │\n",
       "│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 007…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1.2.826.0 ┆ 0.016863  ┆ 0.011341  ┆ 0.054065  ┆ … ┆ 0.010296  ┆ 0.007462  ┆ 0.018473  ┆ 0.0      │\n",
       "│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 002…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1.2.826.0 ┆ 0.018186  ┆ 0.024549  ┆ 0.05438   ┆ … ┆ 0.033935  ┆ 0.021262  ┆ 0.029377  ┆ 0.0      │\n",
       "│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 005…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway()\n",
    "    display(pl.read_parquet('/kaggle/working/submission.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025fc536",
   "metadata": {
    "papermill": {
     "duration": 0.002789,
     "end_time": "2025-10-14T20:45:41.569749",
     "exception": false,
     "start_time": "2025-10-14T20:45:41.566960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13851420,
     "sourceId": 99552,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 472817,
     "modelInstanceId": 456837,
     "sourceId": 608565,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33.649284,
   "end_time": "2025-10-14T20:45:42.791176",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-14T20:45:09.141892",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
